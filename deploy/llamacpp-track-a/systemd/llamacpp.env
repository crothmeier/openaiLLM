# llama.cpp tunables for GPT-OSS-20B (MXFP4)
MODEL=/mnt/nvme/models/gpt-oss-20b/gpt-oss-20b-mxfp4.gguf
HOST=127.0.0.1
PORT=8010
CONTEXT=8192
THREADS=12
NGPU_LAYERS=999
SLOTS=4
